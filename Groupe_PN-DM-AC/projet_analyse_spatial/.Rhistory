# import de data.shp
#data <- as.data.frame(st_read("data/data.shp"))
data_2017_ech <- as.data.frame(st_read("data/echantillon.shp"))
iso <- as.data.frame(st_read("data/isochrones_driving_30min.shp"))
# interpolation
ech <- data_2017_ech[,c("id_mutatio","valeur_fon","longitude","latitude")]
point_plot <- ggplot(
data = ech,
mapping = aes(x = longitude, y = latitude, color = valeur_fon)) +
geom_point(size = 3) +
scale_color_gradientn(colors = c("blue", "yellow", "red"))
#point_plot
bbox <- c(
"xmin" = min(ech$longitude),
"ymin" = min(ech$latitude),
"xmax" = max(ech$longitude),
"ymax" = max(ech$latitude)
)
grd_template <- expand.grid(
X = seq(from = bbox["xmin"], to = bbox["xmax"], by = 20),
Y = seq(from = bbox["ymin"], to = bbox["ymax"], by = 20) # 20 m resolution
)
grid_plot <- ggplot() +
geom_point(data = grd_template, aes(x = X, y = Y), size = 0.01) +
geom_point(data = ech,
mapping = aes(x = longitude, y = latitude, color = valeur_fon), size = 3) +
scale_color_gradientn(colors = c("blue", "yellow", "red")) +
coord_cartesian( #zooming in so we can actually see something
xlim = c(3.55, 4.155), ylim = c(43.42, 43.78)) +
theme_bw()
#grid_plot
sf_ech <- st_as_sf(ech, coords = c("longitude", "latitude"), crs = 25833)
alt_grd_template_sf <- sf_ech %>%
st_bbox() %>%
st_as_sfc() %>%
st_make_grid(
cellsize = c(20, 20),
what = "centers"
) %>%
st_as_sf() %>%
cbind(., st_coordinates(.)) %>%
st_drop_geometry() %>%
mutate(Z = 0)
# We start with functions that return model objects as this is the most
# common case
# Nearest Neighbor
#fit_NN <- gstat::gstat( # using package {gstat}
#  formula = valeur_fon ~ 1,    # The column `valeur_fon` is what we are interested in
#  data = as(sf_ech, "Spatial"), # using {sf} and converting to {sp}, which is expected
#  nmax = 5, nmin = 3 # Number of neighboring observations used for the fit
#)
# Inverse Distance Weighting
fit_IDW <- gstat::gstat( # The setup here is quite similar to NN
formula = valeur_fon ~ 1,
data = as(sf_ech, "Spatial"),
nmax = 5, nmin = 3,
set = list(idp = 0.5) # inverse distance power
)
# Thin Plate Spline Regression
#fit_TPS <- fields::Tps( # using {fields}
#  x = as.matrix(ech[, c("longitude", "latitude")]), # accepts points but expects them as matrix
#  Y = ech$valeur_fon,  # the dependent variable
#  miles = FALSE     # EPSG 25833 is based in meters
#)
# Generalized Additive Model
#fit_GAM <- mgcv::gam( # using {mgcv}
#  valeur_fon ~ s(longitude, latitude),      # here come our X/Y/Z data - straightforward enough
#  data = ech      # specify in which object the data is stored
#)
# Next we use a couple of functions that have a slightly different modus
# operandi as they in fact already return interpolated Z values.
# Triangular Irregular Surface
#fit_TIN <- interp::interp( # using {interp}
#  x = ech$longitude,           # the function actually accepts coordinate vectors
#  y = ech$latitude,
#  z = ech$valeur_fon,
#  xo = grd_template$X,     # here we already define the target grid
#  yo = grd_template$Y,
#  output = "points"
#) %>% bind_cols()
# Automatized Kriging
#fit_KRIG <- automap::autoKrige(      # using {automap}
#  formula = valeur_fon ~ 1,                 # The interface is similar to {gstat} but
#  input_data = as(sf_ech, "Spatial") # {automap} makes a lot of assumptions for you
#) %>%
#  .$krige_output %>%  # the function returns a complex object with lot's of metainfo
#  as.data.frame() %>% # we keep only the data we are interested in
#  dplyr::select(X = x1, Y = x2, Z = var1.pred)
interp_IDW <- raster::rasterFromXYZ(fit_IDW, crs = crs_raster_format)
plot(interp_IDW)
#interp_TIN <- raster::rasterFromXYZ(fit_TIN, crs = crs_raster_format)
# export de data_2017 en csv
#write.csv(data_2017[,c("id_mutatio","valeur_fon","longitude","latitude")],"interpolation/data.csv", row.names = FALSE)
# import des isochrones
#data$date_sec <- as.numeric(gsub("-","",data$date_mutat))
#data$year <- substr(data$date_mutat, 0, 4)
# carte des isochrones
#map_iso <- ggplot(data=iso$geometry) + geom_sf(fill=iso$AA_MINS)
# calcul de la valeur fonciere moyenne au metre caree par isochrone
#data$val_moy_m2 <- data$valeur_fon/data$surface_re
#isochrone_group_mean <- aggregate(val_moy_m2 ~ AA_MINS + year, data = data, FUN = mean)
# jointure avec les isochrones
#geom_iso_grp_mean <- inner_join(isochrone_group_mean,iso[,c("AA_MINS","geometry")],by=c("AA_MINS"))
# graphe d'analyse
#graph_mean <- ggplot(geom_iso_grp_mean, aes(x = year, y = val_moy_m2, color = as.factor(AA_MINS), group = as.factor(AA_MINS))) + geom_point() + geom_line() + labs(x = "Annee", y = "Prix / m2", color = "Isochrone",
#                                    title = "Valeur moyene du m2 par isochrone a Montpellier")
#
#
#
sf_ech
ech
set.seed(1)
setwd("C:/Users/patri/Downloads/data")
# libraries
#install.packages("sf")
library(sf)
#install.packages("ggplot2")
library(ggplot2)
#install.packages("dplyr")
library(dplyr)
# import de data.shp
#data <- as.data.frame(st_read("data/data.shp"))
data_2017_ech <- as.data.frame(st_read("data/echantillon.shp"))
iso <- as.data.frame(st_read("data/isochrones_driving_30min.shp"))
# interpolation
ech <- data_2017_ech[,c("id_mutatio","valeur_fon","longitude","latitude")]
point_plot <- ggplot(
data = ech,
mapping = aes(x = longitude, y = latitude, color = valeur_fon)) +
geom_point(size = 3) +
scale_color_gradientn(colors = c("blue", "yellow", "red"))
#point_plot
bbox <- c(
"xmin" = min(ech$longitude),
"ymin" = min(ech$latitude),
"xmax" = max(ech$longitude),
"ymax" = max(ech$latitude)
)
grd_template <- expand.grid(
X = seq(from = bbox["xmin"], to = bbox["xmax"], by = 20),
Y = seq(from = bbox["ymin"], to = bbox["ymax"], by = 20) # 20 m resolution
)
grid_plot <- ggplot() +
geom_point(data = grd_template, aes(x = X, y = Y), size = 0.01) +
geom_point(data = ech,
mapping = aes(x = longitude, y = latitude, color = valeur_fon), size = 3) +
scale_color_gradientn(colors = c("blue", "yellow", "red")) +
coord_cartesian( #zooming in so we can actually see something
xlim = c(3.55, 4.155), ylim = c(43.42, 43.78)) +
theme_bw()
#grid_plot
sf_ech <- st_as_sf(ech, coords = c("longitude", "latitude"), crs = 25833)
alt_grd_template_sf <- sf_ech %>%
st_bbox() %>%
st_as_sfc() %>%
st_make_grid(
cellsize = c(20, 20),
what = "centers"
) %>%
st_as_sf() %>%
cbind(., st_coordinates(.)) %>%
st_drop_geometry() %>%
mutate(Z = 0)
# We start with functions that return model objects as this is the most
# common case
# Nearest Neighbor
fit_NN <- gstat::gstat( # using package {gstat}
formula = valeur_fon ~ 1,    # The column `valeur_fon` is what we are interested in
data = as(sf_ech, "Spatial"), # using {sf} and converting to {sp}, which is expected
nmax = 5, nmin = 3 # Number of neighboring observations used for the fit
)
# Inverse Distance Weighting
#fit_IDW <- gstat::gstat( # The setup here is quite similar to NN
#  formula = valeur_fon ~ 1,
#  data = as(sf_ech, "Spatial"),
#  nmax = 5, nmin = 3,
#  set = list(idp = 0.5) # inverse distance power
#)
# Thin Plate Spline Regression
#fit_TPS <- fields::Tps( # using {fields}
#  x = as.matrix(ech[, c("longitude", "latitude")]), # accepts points but expects them as matrix
#  Y = ech$valeur_fon,  # the dependent variable
#  miles = FALSE     # EPSG 25833 is based in meters
#)
# Generalized Additive Model
#fit_GAM <- mgcv::gam( # using {mgcv}
#  valeur_fon ~ s(longitude, latitude),      # here come our X/Y/Z data - straightforward enough
#  data = ech      # specify in which object the data is stored
#)
# Next we use a couple of functions that have a slightly different modus
# operandi as they in fact already return interpolated Z values.
# Triangular Irregular Surface
#fit_TIN <- interp::interp( # using {interp}
#  x = ech$longitude,           # the function actually accepts coordinate vectors
#  y = ech$latitude,
#  z = ech$valeur_fon,
#  xo = grd_template$X,     # here we already define the target grid
#  yo = grd_template$Y,
#  output = "points"
#) %>% bind_cols()
# Automatized Kriging
#fit_KRIG <- automap::autoKrige(      # using {automap}
#  formula = valeur_fon ~ 1,                 # The interface is similar to {gstat} but
#  input_data = as(sf_ech, "Spatial") # {automap} makes a lot of assumptions for you
#) %>%
#  .$krige_output %>%  # the function returns a complex object with lot's of metainfo
#  as.data.frame() %>% # we keep only the data we are interested in
#  dplyr::select(X = x1, Y = x2, Z = var1.pred)
interp_NN <- raster::rasterFromXYZ(fit_NN, crs = crs_raster_format)
plot(interp_NN)
#interp_TIN <- raster::rasterFromXYZ(fit_TIN, crs = crs_raster_format)
# export de data_2017 en csv
#write.csv(data_2017[,c("id_mutatio","valeur_fon","longitude","latitude")],"interpolation/data.csv", row.names = FALSE)
# import des isochrones
#data$date_sec <- as.numeric(gsub("-","",data$date_mutat))
#data$year <- substr(data$date_mutat, 0, 4)
# carte des isochrones
#map_iso <- ggplot(data=iso$geometry) + geom_sf(fill=iso$AA_MINS)
# calcul de la valeur fonciere moyenne au metre caree par isochrone
#data$val_moy_m2 <- data$valeur_fon/data$surface_re
#isochrone_group_mean <- aggregate(val_moy_m2 ~ AA_MINS + year, data = data, FUN = mean)
# jointure avec les isochrones
#geom_iso_grp_mean <- inner_join(isochrone_group_mean,iso[,c("AA_MINS","geometry")],by=c("AA_MINS"))
# graphe d'analyse
#graph_mean <- ggplot(geom_iso_grp_mean, aes(x = year, y = val_moy_m2, color = as.factor(AA_MINS), group = as.factor(AA_MINS))) + geom_point() + geom_line() + labs(x = "Annee", y = "Prix / m2", color = "Isochrone",
#                                    title = "Valeur moyene du m2 par isochrone a Montpellier")
#
#
#
set.seed(1)
setwd("C:/Users/patri/Downloads/data")
# libraries
#install.packages("sf")
library(sf)
#install.packages("ggplot2")
library(ggplot2)
#install.packages("dplyr")
library(dplyr)
# import de data.shp
#data <- as.data.frame(st_read("data/data.shp"))
data_2017_ech <- as.data.frame(st_read("data/echantillon.shp"))
iso <- as.data.frame(st_read("data/isochrones_driving_30min.shp"))
# interpolation
ech <- data_2017_ech[,c("id_mutatio","valeur_fon","longitude","latitude")]
point_plot <- ggplot(
data = ech,
mapping = aes(x = longitude, y = latitude, color = valeur_fon)) +
geom_point(size = 3) +
scale_color_gradientn(colors = c("blue", "yellow", "red"))
#point_plot
bbox <- c(
"xmin" = min(ech$longitude),
"ymin" = min(ech$latitude),
"xmax" = max(ech$longitude),
"ymax" = max(ech$latitude)
)
grd_template <- expand.grid(
X = seq(from = bbox["xmin"], to = bbox["xmax"], by = 20),
Y = seq(from = bbox["ymin"], to = bbox["ymax"], by = 20) # 20 m resolution
)
grid_plot <- ggplot() +
geom_point(data = grd_template, aes(x = X, y = Y), size = 0.01) +
geom_point(data = ech,
mapping = aes(x = longitude, y = latitude, color = valeur_fon), size = 3) +
scale_color_gradientn(colors = c("blue", "yellow", "red")) +
coord_cartesian( #zooming in so we can actually see something
xlim = c(3.55, 4.155), ylim = c(43.42, 43.78)) +
theme_bw()
#grid_plot
sf_ech <- st_as_sf(ech, coords = c("longitude", "latitude"), crs = 25833)
alt_grd_template_sf <- sf_ech %>%
st_bbox() %>%
st_as_sfc() %>%
st_make_grid(
cellsize = c(20, 20),
what = "centers"
) %>%
st_as_sf() %>%
cbind(., st_coordinates(.)) %>%
st_drop_geometry() %>%
mutate(Z = 0)
# We start with functions that return model objects as this is the most
# common case
# Nearest Neighbor
#fit_NN <- gstat::gstat( # using package {gstat}
#  formula = valeur_fon ~ 1,    # The column `valeur_fon` is what we are interested in
#  data = as(sf_ech, "Spatial"), # using {sf} and converting to {sp}, which is expected
#  nmax = 5, nmin = 3 # Number of neighboring observations used for the fit
#)
# Inverse Distance Weighting
#fit_IDW <- gstat::gstat( # The setup here is quite similar to NN
#  formula = valeur_fon ~ 1,
#  data = as(sf_ech, "Spatial"),
#  nmax = 5, nmin = 3,
#  set = list(idp = 0.5) # inverse distance power
#)
# Thin Plate Spline Regression
#fit_TPS <- fields::Tps( # using {fields}
#  x = as.matrix(ech[, c("longitude", "latitude")]), # accepts points but expects them as matrix
#  Y = ech$valeur_fon,  # the dependent variable
#  miles = FALSE     # EPSG 25833 is based in meters
#)
# Generalized Additive Model
#fit_GAM <- mgcv::gam( # using {mgcv}
#  valeur_fon ~ s(longitude, latitude),      # here come our X/Y/Z data - straightforward enough
#  data = ech      # specify in which object the data is stored
#)
# Next we use a couple of functions that have a slightly different modus
# operandi as they in fact already return interpolated Z values.
# Triangular Irregular Surface
fit_TIN <- interp::interp( # using {interp}
x = ech$longitude,           # the function actually accepts coordinate vectors
y = ech$latitude,
z = ech$valeur_fon,
xo = grd_template$X,     # here we already define the target grid
yo = grd_template$Y,
output = "points"
) %>% bind_cols()
# Automatized Kriging
#fit_KRIG <- automap::autoKrige(      # using {automap}
#  formula = valeur_fon ~ 1,                 # The interface is similar to {gstat} but
#  input_data = as(sf_ech, "Spatial") # {automap} makes a lot of assumptions for you
#) %>%
#  .$krige_output %>%  # the function returns a complex object with lot's of metainfo
#  as.data.frame() %>% # we keep only the data we are interested in
#  dplyr::select(X = x1, Y = x2, Z = var1.pred)
interp_TIN <- raster::rasterFromXYZ(fit_TIN, crs = crs_raster_format)
plot(interp_TIN)
#interp_TIN <- raster::rasterFromXYZ(fit_TIN, crs = crs_raster_format)
# export de data_2017 en csv
#write.csv(data_2017[,c("id_mutatio","valeur_fon","longitude","latitude")],"interpolation/data.csv", row.names = FALSE)
# import des isochrones
#data$date_sec <- as.numeric(gsub("-","",data$date_mutat))
#data$year <- substr(data$date_mutat, 0, 4)
# carte des isochrones
#map_iso <- ggplot(data=iso$geometry) + geom_sf(fill=iso$AA_MINS)
# calcul de la valeur fonciere moyenne au metre caree par isochrone
#data$val_moy_m2 <- data$valeur_fon/data$surface_re
#isochrone_group_mean <- aggregate(val_moy_m2 ~ AA_MINS + year, data = data, FUN = mean)
# jointure avec les isochrones
#geom_iso_grp_mean <- inner_join(isochrone_group_mean,iso[,c("AA_MINS","geometry")],by=c("AA_MINS"))
# graphe d'analyse
#graph_mean <- ggplot(geom_iso_grp_mean, aes(x = year, y = val_moy_m2, color = as.factor(AA_MINS), group = as.factor(AA_MINS))) + geom_point() + geom_line() + labs(x = "Annee", y = "Prix / m2", color = "Isochrone",
#                                    title = "Valeur moyene du m2 par isochrone a Montpellier")
#
#
#
set.seed(1)
setwd("C:/Users/patri/Downloads/data")
# libraries
#install.packages("sf")
library(sf)
#install.packages("ggplot2")
library(ggplot2)
#install.packages("dplyr")
library(dplyr)
# import de data.shp
#data <- as.data.frame(st_read("data/data.shp"))
data_2017_ech <- as.data.frame(st_read("data/echantillon.shp"))
iso <- as.data.frame(st_read("data/isochrones_driving_30min.shp"))
# interpolation
ech <- data_2017_ech[,c("id_mutatio","valeur_fon","longitude","latitude")]
point_plot <- ggplot(
data = ech,
mapping = aes(x = longitude, y = latitude, color = valeur_fon)) +
geom_point(size = 3) +
scale_color_gradientn(colors = c("blue", "yellow", "red"))
#point_plot
bbox <- c(
"xmin" = min(ech$longitude),
"ymin" = min(ech$latitude),
"xmax" = max(ech$longitude),
"ymax" = max(ech$latitude)
)
grd_template <- expand.grid(
X = seq(from = bbox["xmin"], to = bbox["xmax"], by = 20),
Y = seq(from = bbox["ymin"], to = bbox["ymax"], by = 20) # 20 m resolution
)
grid_plot <- ggplot() +
geom_point(data = grd_template, aes(x = X, y = Y), size = 0.01) +
geom_point(data = ech,
mapping = aes(x = longitude, y = latitude, color = valeur_fon), size = 3) +
scale_color_gradientn(colors = c("blue", "yellow", "red")) +
coord_cartesian( #zooming in so we can actually see something
xlim = c(3.55, 4.155), ylim = c(43.42, 43.78)) +
theme_bw()
#grid_plot
sf_ech <- st_as_sf(ech, coords = c("longitude", "latitude"), crs = 25833)
alt_grd_template_sf <- sf_ech %>%
st_bbox() %>%
st_as_sfc() %>%
st_make_grid(
cellsize = c(20, 20),
what = "centers"
) %>%
st_as_sf() %>%
cbind(., st_coordinates(.)) %>%
st_drop_geometry() %>%
mutate(Z = 0)
# We start with functions that return model objects as this is the most
# common case
# Nearest Neighbor
#fit_NN <- gstat::gstat( # using package {gstat}
#  formula = valeur_fon ~ 1,    # The column `valeur_fon` is what we are interested in
#  data = as(sf_ech, "Spatial"), # using {sf} and converting to {sp}, which is expected
#  nmax = 5, nmin = 3 # Number of neighboring observations used for the fit
#)
# Inverse Distance Weighting
#fit_IDW <- gstat::gstat( # The setup here is quite similar to NN
#  formula = valeur_fon ~ 1,
#  data = as(sf_ech, "Spatial"),
#  nmax = 5, nmin = 3,
#  set = list(idp = 0.5) # inverse distance power
#)
# Thin Plate Spline Regression
#fit_TPS <- fields::Tps( # using {fields}
#  x = as.matrix(ech[, c("longitude", "latitude")]), # accepts points but expects them as matrix
#  Y = ech$valeur_fon,  # the dependent variable
#  miles = FALSE     # EPSG 25833 is based in meters
#)
# Generalized Additive Model
#fit_GAM <- mgcv::gam( # using {mgcv}
#  valeur_fon ~ s(longitude, latitude),      # here come our X/Y/Z data - straightforward enough
#  data = ech      # specify in which object the data is stored
#)
# Next we use a couple of functions that have a slightly different modus
# operandi as they in fact already return interpolated Z values.
# Triangular Irregular Surface
#fit_TIN <- interp::interp( # using {interp}
##  x = ech$longitude,           # the function actually accepts coordinate vectors
#  y = ech$latitude,
#  z = ech$valeur_fon,
#  xo = grd_template$X,     # here we already define the target grid
#  yo = grd_template$Y,
#  output = "points"
#) %>% bind_cols()
# Automatized Kriging
fit_KRIG <- automap::autoKrige(      # using {automap}
formula = valeur_fon ~ 1,                 # The interface is similar to {gstat} but
input_data = as(sf_ech, "Spatial") # {automap} makes a lot of assumptions for you
) %>%
.$krige_output %>%  # the function returns a complex object with lot's of metainfo
as.data.frame() %>% # we keep only the data we are interested in
dplyr::select(X = x1, Y = x2, Z = var1.pred)
interp_KRIG <- raster::rasterFromXYZ(fit_KRIG, crs = crs_raster_format)
plot(interp_KRIG)
#interp_TIN <- raster::rasterFromXYZ(fit_TIN, crs = crs_raster_format)
# export de data_2017 en csv
#write.csv(data_2017[,c("id_mutatio","valeur_fon","longitude","latitude")],"interpolation/data.csv", row.names = FALSE)
# import des isochrones
#data$date_sec <- as.numeric(gsub("-","",data$date_mutat))
#data$year <- substr(data$date_mutat, 0, 4)
# carte des isochrones
#map_iso <- ggplot(data=iso$geometry) + geom_sf(fill=iso$AA_MINS)
# calcul de la valeur fonciere moyenne au metre caree par isochrone
#data$val_moy_m2 <- data$valeur_fon/data$surface_re
#isochrone_group_mean <- aggregate(val_moy_m2 ~ AA_MINS + year, data = data, FUN = mean)
# jointure avec les isochrones
#geom_iso_grp_mean <- inner_join(isochrone_group_mean,iso[,c("AA_MINS","geometry")],by=c("AA_MINS"))
# graphe d'analyse
#graph_mean <- ggplot(geom_iso_grp_mean, aes(x = year, y = val_moy_m2, color = as.factor(AA_MINS), group = as.factor(AA_MINS))) + geom_point() + geom_line() + labs(x = "Annee", y = "Prix / m2", color = "Isochrone",
#                                    title = "Valeur moyene du m2 par isochrone a Montpellier")
#
#
#
set.seed(1)
setwd("C:/Users/patri/Downloads/data")
# libraries
#install.packages("sf")
library(sf)
#install.packages("ggplot2")
library(ggplot2)
#install.packages("dplyr")
library(dplyr)
# import de data.shp
#data <- as.data.frame(st_read("data/data.shp"))
data_2017_ech <- as.data.frame(st_read("data/echantillon.shp"))
iso <- as.data.frame(st_read("data/isochrones_driving_30min.shp"))
# interpolation
ech <- data_2017_ech[,c("id_mutatio","valeur_fon","longitude","latitude")]
point_plot <- ggplot(
data = ech,
mapping = aes(x = longitude, y = latitude, color = valeur_fon)) +
geom_point(size = 3) +
scale_color_gradientn(colors = c("blue", "yellow", "red"))
#point_plot
#install.packages(akima)
library("akima")
Interpole <- with(ech, interp(x = ech$longitude, y = ech$latitude,
z = ech$valeur_fon, xo = seq(from = 3.5, to = 5, by = 0.01),
yo = seq(from = 43.2, to = 43.9, by = 0.01)))
image(Interpole, col = topo.colors(128, alpha = 1), asp = 1)
contour(Interpole, add = TRUE)
with(ech, points(x = ech$longitude, y = ech$latitude, pch = 20))
# export de data_2017 en csv
#write.csv(data_2017[,c("id_mutatio","valeur_fon","longitude","latitude")],"interpolation/data.csv", row.names = FALSE)
# import des isochrones
#data$date_sec <- as.numeric(gsub("-","",data$date_mutat))
#data$year <- substr(data$date_mutat, 0, 4)
# carte des isochrones
#map_iso <- ggplot(data=iso$geometry) + geom_sf(fill=iso$AA_MINS)
# calcul de la valeur fonciere moyenne au metre caree par isochrone
#data$val_moy_m2 <- data$valeur_fon/data$surface_re
#isochrone_group_mean <- aggregate(val_moy_m2 ~ AA_MINS + year, data = data, FUN = mean)
# jointure avec les isochrones
#geom_iso_grp_mean <- inner_join(isochrone_group_mean,iso[,c("AA_MINS","geometry")],by=c("AA_MINS"))
# graphe d'analyse
#graph_mean <- ggplot(geom_iso_grp_mean, aes(x = year, y = val_moy_m2, color = as.factor(AA_MINS), group = as.factor(AA_MINS))) + geom_point() + geom_line() + labs(x = "Annee", y = "Prix / m2", color = "Isochrone",
#                                    title = "Valeur moyene du m2 par isochrone a Montpellier")
#
#
#
